{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f476c53c-1e6d-40b2-ba0a-2f03582b9bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27add531-30b8-4557-8c4f-147ce77d25df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 Data:\n",
      "{'Project Name': 'Kasturi Developers\\nBUILDER\\n-', 'Project Price': '35,000', 'Builtup Area': '1700', 'BHK': '3', 'Deposit': 'No Deposit', 'Bathrooms': '3 bathrooms', 'Facing': 'NorthEast facing'}\n",
      "{'Project Name': 'Kasturi Developers\\nBUILDER\\n-', 'Project Price': '20,000', 'Builtup Area': '1200', 'BHK': '2', 'Deposit': 'No Deposit', 'Bathrooms': '2 bathrooms', 'Facing': 'NorthEast facing'}\n",
      "{'Project Name': 'Kasturi Developers\\nBUILDER\\n-', 'Project Price': '30,000', 'Builtup Area': '1700', 'BHK': '3', 'Deposit': 'No Deposit', 'Bathrooms': '3 bathrooms', 'Facing': 'NorthEast facing'}\n",
      "{'Project Name': 'Seller\\nVERIFIED OWNER', 'Project Price': '28,500', 'Builtup Area': '750', 'BHK': '2', 'Deposit': 'No Deposit', 'Bathrooms': '2 bathrooms', 'Facing': None}\n",
      "{'Project Name': 'Seller\\nVERIFIED OWNER', 'Project Price': '50,000', 'Builtup Area': '1400', 'BHK': '3', 'Deposit': 'No Deposit', 'Bathrooms': '3 bathrooms', 'Facing': 'East facing'}\n",
      "{'Project Name': 'Seller\\nVERIFIED OWNER', 'Project Price': '3,000', 'Builtup Area': '450', 'BHK': '1', 'Deposit': 'No Deposit', 'Bathrooms': '1 bathrooms', 'Facing': 'East facing'}\n",
      "{'Project Name': 'Seller\\nVERIFIED OWNER', 'Project Price': '9,500', 'Builtup Area': '700', 'BHK': '1', 'Deposit': 'No Deposit', 'Bathrooms': '2 bathrooms', 'Facing': None}\n",
      "{'Project Name': 'Seller\\nVERIFIED OWNER', 'Project Price': '55,000', 'Builtup Area': '600', 'BHK': '1', 'Deposit': 'No Deposit', 'Bathrooms': '2 bathrooms', 'Facing': None}\n",
      "{'Project Name': 'CHERRISH ESTATE CONSULTANTS\\nAGENT\\n-', 'Project Price': '50,000', 'Builtup Area': '600', 'BHK': '1', 'Deposit': 'No Deposit', 'Bathrooms': '2 bathrooms', 'Facing': 'East facing'}\n",
      "{'Project Name': 'Kharghar Homes\\nAGENT\\n-', 'Project Price': '9,000', 'Builtup Area': '510', 'BHK': '1', 'Deposit': 'No Deposit', 'Bathrooms': '1 bathrooms', 'Facing': 'East facing'}\n",
      "{'Project Name': 'Ankur Real Estate Agent Palghar\\nAGENT\\n-', 'Project Price': '4,500', 'Builtup Area': '650', 'BHK': '1', 'Deposit': 'No Deposit', 'Bathrooms': '2 bathrooms', 'Facing': 'West facing'}\n",
      "{'Project Name': 'ROYAL REALTY\\nAGENT\\n-', 'Project Price': '77,000', 'Builtup Area': '1300', 'BHK': '3', 'Deposit': 'No Deposit', 'Bathrooms': '2 bathrooms', 'Facing': None}\n",
      "{'Project Name': 'Balaji Propiedad\\nAGENT\\n-', 'Project Price': '50,000', 'Builtup Area': '865', 'BHK': '2', 'Deposit': 'No Deposit', 'Bathrooms': '2 bathrooms', 'Facing': None}\n",
      "{'Project Name': 'Sakshi Esate Consultancy\\nAGENT\\n-', 'Project Price': '24,000', 'Builtup Area': '750', 'BHK': '1', 'Deposit': 'No Deposit', 'Bathrooms': '2 bathrooms', 'Facing': None}\n",
      "{'Project Name': 'Kalyani Real Estate\\nAGENT\\n-', 'Project Price': '25,000', 'Builtup Area': '830', 'BHK': '2', 'Deposit': 'No Deposit', 'Bathrooms': '2 bathrooms', 'Facing': 'East facing'}\n",
      "{'Project Name': 'Individual Agent\\nAGENT\\n-', 'Project Price': '50,000', 'Builtup Area': '900', 'BHK': '2', 'Deposit': 'No Deposit', 'Bathrooms': '2 bathrooms', 'Facing': None}\n",
      "{'Project Name': 'Home On Sense Enterprises\\nAGENT\\n-', 'Project Price': '9,000', 'Builtup Area': '960', 'BHK': '2', 'Deposit': 'No Deposit', 'Bathrooms': '2 bathrooms', 'Facing': 'East facing'}\n",
      "{'Project Name': 'Arise Real Estate And Consultant\\nAGENT\\n-', 'Project Price': '72,000', 'Builtup Area': '700', 'BHK': '2', 'Deposit': 'No Deposit', 'Bathrooms': '3 bathrooms', 'Facing': 'West facing'}\n",
      "{'Project Name': 'The Great Royal Estate Agency\\nAGENT\\n-', 'Project Price': '82,000', 'Builtup Area': '1500', 'BHK': '3', 'Deposit': 'No Deposit', 'Bathrooms': '3 bathrooms', 'Facing': 'North facing'}\n",
      "{'Project Name': 'AN Properties\\nAGENT\\n-', 'Project Price': '31,000', 'Builtup Area': '450', 'BHK': '1', 'Deposit': 'No Deposit', 'Bathrooms': '1 bathrooms', 'Facing': None}\n",
      "-- done --\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "\n",
    "# Function to save data to CSV file\n",
    "def save_to_csv(data, filename):\n",
    "    if data:\n",
    "        keys = data[0].keys()\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=keys)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(data)\n",
    "    else:\n",
    "        print(\"No data to save.\")\n",
    "\n",
    "\n",
    "# Start the browser\n",
    "service = Service(executable_path='/snap/bin/geckodriver')\n",
    "browser = webdriver.Firefox(service=service)\n",
    "\n",
    "\n",
    "def extract_data(browser):\n",
    "    data_list = []\n",
    "    try:\n",
    "        parent_div = WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"list-mainarea\")))\n",
    "        project_wrappers = parent_div.find_elements(By.CLASS_NAME, \"cardholder\")\n",
    "        for project_wrapper in project_wrappers:\n",
    "            try:\n",
    "                project_name = project_wrapper.find_element(By.CLASS_NAME, \"seller-info\").text\n",
    "                project_price = project_wrapper.find_element(By.CLASS_NAME, \"price\").text\n",
    "                builtup_area = project_wrapper.find_element(By.CLASS_NAME, \"size\").text\n",
    "                bhk = project_wrapper.find_element(By.CLASS_NAME, \"val\").text\n",
    "\n",
    "\n",
    "                # Extracting additional details\n",
    "                details_ul = project_wrapper.find_element(By.CLASS_NAME, \"listing-details\")\n",
    "                details_li = details_ul.find_elements(By.CLASS_NAME, \"keypoint\")\n",
    "\n",
    "                deposit = None\n",
    "                bathrooms = None\n",
    "                facing = None\n",
    "\n",
    "                for li in details_li:\n",
    "                    title = li.get_attribute(\"title\")\n",
    "                    if title == \"deposit\":\n",
    "                        deposit = li.text.strip()\n",
    "                    elif title == \"bathrooms\":\n",
    "                        bathrooms = li.find_element(By.TAG_NAME, \"span\").text\n",
    "                    elif title == \"facing\":\n",
    "                        facing = li.text.strip()\n",
    "\n",
    "                # Adding all details to the data list\n",
    "                data_list.append({\n",
    "                    \"Project Name\": project_name,\n",
    "                    \"Project Price\": project_price,\n",
    "                    \"Builtup Area\": builtup_area,\n",
    "                    \"BHK\": bhk,\n",
    "                    \"Deposit\": deposit,\n",
    "                    \"Bathrooms\": bathrooms,\n",
    "                    \"Facing\": facing\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting data for a project: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping data: {e}\")\n",
    "    return data_list\n",
    "\n",
    "\n",
    "base_url = 'https://www.makaan.com/listings?listingType=rent&pageType=CITY_URLS&cityName=Mumbai&cityId=18&templateId=MAKAAN_CITY_LISTING_BUY&page='\n",
    "page_count = 1\n",
    "all_data = []\n",
    "\n",
    "# Loop through each page\n",
    "for page in range(1, page_count + 1):\n",
    "    url = base_url + str(page)\n",
    "    browser.get(url)\n",
    "    # Add a delay to ensure page loads completely\n",
    "    time.sleep(5)\n",
    "    page_data = extract_data(browser)\n",
    "    print(f\"Page {page} Data:\")\n",
    "    for project in page_data:\n",
    "        print(project)\n",
    "    all_data.extend(page_data)\n",
    "\n",
    "# Close the browser properly\n",
    "browser.quit()\n",
    "\n",
    "# Write all_data to CSV file\n",
    "save_to_csv(all_data, 'data.csv')\n",
    "\n",
    "print(\"-- done --\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "629888e9-a1c5-4458-8482-b1ddbbe29f2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutException",
     "evalue": "Message: \n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Wait for the property listings to load\u001b[39;00m\n\u001b[1;32m     31\u001b[0m wait \u001b[38;5;241m=\u001b[39m WebDriverWait(browser, \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m property_listings \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpresence_of_all_elements_located\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLASS_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcard\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# List to hold the scraped data\u001b[39;00m\n\u001b[1;32m     35\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/selenium/webdriver/support/wait.py:105\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m>\u001b[39m end_time:\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[0;31mTimeoutException\u001b[0m: Message: \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# Function to save data to CSV file\n",
    "def save_to_csv(data, filename):\n",
    "    if data:\n",
    "        keys = data[0].keys()\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=keys)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(data)\n",
    "    else:\n",
    "        print(\"No data to save.\")\n",
    "\n",
    "# Start the browser\n",
    "service = Service(executable_path='/snap/bin/geckodriver')\n",
    "browser = webdriver.Firefox(service=service)\n",
    "\n",
    "# URL of the webpage to scrape\n",
    "url = \"https://www.nobroker.in/property/rent/mumbai/Mumbai%20Central?searchParam=W3sibGF0IjoxOC45NjkwMjQ3LCJsb24iOjcyLjgyMDUyOTIsInBsYWNlSWQiOiJDaElKTjNHeG9XN081enNSNF9YTE83R09HZjQiLCJwbGFjZU5hbWUiOiJNdW1iYWkgQ2VudHJhbCJ9XQ==&radius=2.0&sharedAccomodation=0&city=mumbai&locality=Mumbai%20Central\"\n",
    "\n",
    "# Open the webpage\n",
    "browser.get(url)\n",
    "\n",
    "# Wait for the property listings to load\n",
    "wait = WebDriverWait(browser, 10)\n",
    "property_listings = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, 'card')))\n",
    "\n",
    "# List to hold the scraped data\n",
    "data = []\n",
    "\n",
    "# Extract information for each property\n",
    "for property in property_listings:\n",
    "    try:\n",
    "        rent = property.find_element(By.CLASS_NAME, 'heading-6').text.strip()\n",
    "        location = property.find_element(By.CLASS_NAME, 'component__locality--fNwDM').text.strip()\n",
    "        apartment_type = property.find_element(By.XPATH, \".//span[contains(@class, 'heading-6')]\").text.strip()\n",
    "        area = property.find_element(By.XPATH, \".//div[contains(@class, 'font-semi-bold') and contains(@class, 'margin-5')]\").text.strip()\n",
    "        deposit = property.find_element(By.XPATH, \".//div[contains(@class, 'font-semi-bold') and contains(@class, 'margin-5')]\").text.strip()\n",
    "        furnishing = property.find_element(By.XPATH, \".//div[contains(@class, 'font-semi-bold') and not(contains(@class, 'margin-5'))]\").text.strip()\n",
    "        preferred_tenant = property.find_element(By.XPATH, \".//div[contains(@class, 'font-semi-bold') and not(contains(@class, 'margin-5'))]\").text.strip()\n",
    "        age_of_building = property.find_element(By.XPATH, \".//div[contains(@class, 'font-semi-bold') and not(contains(@class, 'margin-5'))]\").text.strip()\n",
    "\n",
    "        # Append the data to the list\n",
    "        data.append({\n",
    "            \"Rent\": rent,\n",
    "            \"Location\": location,\n",
    "            \"Apartment Type\": apartment_type,\n",
    "            \"Area\": area,\n",
    "            \"Deposit\": deposit,\n",
    "            \"Furnishing\": furnishing,\n",
    "            \"Preferred Tenant\": preferred_tenant,\n",
    "            \"Age of Building\": age_of_building\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        continue\n",
    "\n",
    "# Save the data to CSV\n",
    "save_to_csv(data, 'rental_properties.csv')\n",
    "\n",
    "# Close the browser\n",
    "browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b959166e-e52e-44a7-a439-3bddf0603623",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TimeoutException' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 32\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m     property_listings \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpresence_of_all_elements_located\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLASS_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnb__2JHKO\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# List to hold the scraped data\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/selenium/webdriver/support/wait.py:105\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[0;31mTimeoutException\u001b[0m: Message: \n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 67\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Save the data to CSV\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     save_to_csv(data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrental_properties.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[43mTimeoutException\u001b[49m:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimeout occurred while waiting for property listings to load\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# Close the browser\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TimeoutException' is not defined"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "\n",
    "# Function to save data to CSV file\n",
    "def save_to_csv(data, filename):\n",
    "    if data:\n",
    "        keys = data[0].keys()\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=keys)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(data)\n",
    "    else:\n",
    "        print(\"No data to save.\")\n",
    "\n",
    "# Start the browser\n",
    "service = Service(executable_path='/snap/bin/geckodriver')\n",
    "browser = webdriver.Firefox(service=service)\n",
    "\n",
    "# URL of the webpage to scrape\n",
    "url = \"https://www.nobroker.in/property/rent/mumbai/Mumbai%20Central?searchParam=W3sibGF0IjoxOC45NjkwMjQ3LCJsb24iOjcyLjgyMDUyOTIsInBsYWNlSWQiOiJDaElKTjNHeG9XN081enNSNF9YTE83R09HZjQiLCJwbGFjZU5hbWUiOiJNdW1iYWkgQ2VudHJhbCJ9XQ==&radius=2.0&sharedAccomodation=0&city=mumbai&locality=Mumbai%20Central\"\n",
    "\n",
    "# Open the webpage\n",
    "browser.get(url)\n",
    "\n",
    "# Wait for the property listings to load\n",
    "wait = WebDriverWait(browser, 20)  # Increasing timeout to 20 seconds\n",
    "try:\n",
    "    property_listings = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, 'nb__2JHKO')))\n",
    "\n",
    "    # List to hold the scraped data\n",
    "    data = []\n",
    "\n",
    "    # Extract information for each property\n",
    "    for property in property_listings:\n",
    "        try:\n",
    "            rent = property.find_element(By.CLASS_NAME, 'nb__3CnI6').text.strip()\n",
    "            location = property.find_element(By.CLASS_NAME, 'nb__35Ol7').text.strip()\n",
    "            apartment_type = property.find_element(By.CLASS_NAME, 'nb__2xbus').text.strip()\n",
    "            area = property.find_element(By.CLASS_NAME, 'nb__3oNyC').text.strip()\n",
    "            deposit = property.find_element(By.CLASS_NAME, 'nb__2NPHR').text.strip()\n",
    "            furnishing = property.find_element(By.CLASS_NAME, 'nb__2IMzv').text.strip()\n",
    "            preferred_tenant = property.find_element(By.CLASS_NAME, 'nb__2dW7A').text.strip()\n",
    "            age_of_building = property.find_element(By.CLASS_NAME, 'nb__2rRJH').text.strip()\n",
    "\n",
    "            # Append the data to the list\n",
    "            data.append({\n",
    "                \"Rent\": rent,\n",
    "                \"Location\": location,\n",
    "                \"Apartment Type\": apartment_type,\n",
    "                \"Area\": area,\n",
    "                \"Deposit\": deposit,\n",
    "                \"Furnishing\": furnishing,\n",
    "                \"Preferred Tenant\": preferred_tenant,\n",
    "                \"Age of Building\": age_of_building\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Save the data to CSV\n",
    "    save_to_csv(data, 'rental_properties.csv')\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Timeout occurred while waiting for property listings to load\")\n",
    "\n",
    "finally:\n",
    "    # Close the browser\n",
    "    browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d88b92-759c-4d53-bb0a-b8261cf2d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import progressbar\n",
    "\n",
    "\n",
    "def scrape_nobroker_rentals(url_pattern, max_pages):\n",
    "    titles = []\n",
    "    addresses = []\n",
    "    rents = []\n",
    "    sizes = []\n",
    "    deposits = []\n",
    "    furnishings = []\n",
    "    property_ages = []\n",
    "    available_fors = []\n",
    "    immediate_possessions = []\n",
    "\n",
    "    bar = progressbar.ProgressBar(maxval=max_pages)\n",
    "    bar.start()\n",
    "\n",
    "    driver = webdriver.Chrome()  # Assuming you are using Chrome WebDriver, adjust if necessary\n",
    "    driver.maximize_window()\n",
    "\n",
    "    for page in range(1, max_pages + 1):\n",
    "        bar.update(page)\n",
    "        link = url_pattern.format(page)\n",
    "        driver.get(link)\n",
    "\n",
    "        # Wait for the page to load (adjust waiting time according to your network speed)\n",
    "        time.sleep(random.uniform(2, 4))\n",
    "\n",
    "        # Extract data from the current page\n",
    "        house_containers = driver.find_elements_by_class_name(\"card\")\n",
    "\n",
    "        if not house_containers:\n",
    "            break\n",
    "\n",
    "        for container in house_containers:\n",
    "            try:\n",
    "                rent = container.find_element_by_xpath('.//h3[3]/span').text.replace(',', '')\n",
    "                rents.append(int(rent))\n",
    "            except:\n",
    "                rents.append('-')\n",
    "\n",
    "            try:\n",
    "                size = int(container.find_element_by_xpath('.//h3[1]/span').text.replace(',', ''))\n",
    "                sizes.append(size)\n",
    "            except:\n",
    "                sizes.append('-')\n",
    "\n",
    "            try:\n",
    "                deposit = int(container.find_element_by_xpath('.//h3[2]/span').text.replace(',', ''))\n",
    "                deposits.append(deposit)\n",
    "            except:\n",
    "                deposits.append('-')\n",
    "\n",
    "            titles.append(container.find_element_by_class_name('card-header-title').find_element_by_tag_name('h2').text.strip())\n",
    "            addresses.append(container.find_element_by_class_name('card-header-title').find_element_by_tag_name('h5').text.strip())\n",
    "            furnishing = container.find_element_by_class_name('detail-summary').find_elements_by_tag_name('h5')[0].text.strip()\n",
    "            furnishings.append(furnishing)\n",
    "            property_age = container.find_element_by_class_name('detail-summary').find_elements_by_tag_name('h5')[1].text.strip()\n",
    "            property_ages.append(property_age)\n",
    "            available_for = container.find_element_by_class_name('detail-summary').find_elements_by_tag_name('h5')[2].text.strip()\n",
    "            available_fors.append(available_for)\n",
    "            immediate_possession = container.find_element_by_class_name('detail-summary').find_elements_by_tag_name('h5')[3].text.strip()\n",
    "            immediate_possessions.append(immediate_possession)\n",
    "\n",
    "        time.sleep(random.uniform(1, 2))\n",
    "\n",
    "    bar.finish()\n",
    "    print(\"Successfully scraped {} pages containing {} properties.\".format(page, len(titles)))\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'Title': titles,\n",
    "        'Address': addresses,\n",
    "        'Rent(Rs)': rents,\n",
    "        'Deposit(Rs)': deposits,\n",
    "        'Size(Acres)': sizes,\n",
    "        'Furnishing': furnishings,\n",
    "        'Property age': property_ages,\n",
    "        'Available for': available_fors,\n",
    "        'Immediate possession': immediate_possessions\n",
    "    })\n",
    "\n",
    "\n",
    "# Define the URL pattern and maximum number of pages to scrape\n",
    "url_pattern = \"https://www.nobroker.in/property/rent/chennai/Chennai/?searchParam=W3sibGF0IjoxMy4wNDM3NjEyODI5MTkyLCJsb24iOjgwLjIwMDA2ODUxNjk2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8402bcc-969b-4359-a2a7-91941047fb9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'progressbar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mprogressbar\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscrape_nobroker_rentals\u001b[39m(url, max_pages):\n\u001b[1;32m     12\u001b[0m     titles \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'progressbar'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import progressbar\n",
    "\n",
    "def scrape_nobroker_rentals(url, max_pages):\n",
    "    titles = []\n",
    "    addresses = []\n",
    "    rents = []\n",
    "    sizes = []\n",
    "    deposits = []\n",
    "    furnishings = []\n",
    "    property_ages = []\n",
    "    available_fors = []\n",
    "    immediate_possessions = []\n",
    "\n",
    "    bar = progressbar.ProgressBar(maxval=max_pages)\n",
    "    bar.start()\n",
    "\n",
    "    service = Service(executable_path='/snap/bin/geckodriver')  # Adjust geckodriver path as per your system\n",
    "    browser = webdriver.Firefox(service=service)\n",
    "\n",
    "    for page in range(1, max_pages + 1):\n",
    "        bar.update(page)\n",
    "        link = f\"{url}&pageNo={page}\"\n",
    "        browser.get(link)\n",
    "\n",
    "        time.sleep(random.uniform(2, 4))  # Add some random delay to simulate human-like behavior\n",
    "\n",
    "        # Extract data from the current page\n",
    "        house_containers = browser.find_elements(By.CLASS_NAME, \"card\")\n",
    "\n",
    "        if not house_containers:\n",
    "            break\n",
    "\n",
    "        for container in house_containers:\n",
    "            try:\n",
    "                rent = container.find_element(By.XPATH, './/h3[3]/span').text.replace(',', '')\n",
    "                rents.append(int(rent))\n",
    "            except:\n",
    "                rents.append('-')\n",
    "\n",
    "            try:\n",
    "                size = int(container.find_element(By.XPATH, './/h3[1]/span').text.replace(',', ''))\n",
    "                sizes.append(size)\n",
    "            except:\n",
    "                sizes.append('-')\n",
    "\n",
    "            try:\n",
    "                deposit = int(container.find_element(By.XPATH, './/h3[2]/span').text.replace(',', ''))\n",
    "                deposits.append(deposit)\n",
    "            except:\n",
    "                deposits.append('-')\n",
    "\n",
    "            titles.append(container.find_element(By.CLASS_NAME, 'card-header-title').find_element(By.TAG_NAME, 'h2').text.strip())\n",
    "            addresses.append(container.find_element(By.CLASS_NAME, 'card-header-title').find_element(By.TAG_NAME, 'h5').text.strip())\n",
    "            furnishing = container.find_element(By.CLASS_NAME, 'detail-summary').find_elements(By.TAG_NAME, 'h5')[0].text.strip()\n",
    "            furnishings.append(furnishing)\n",
    "            property_age = container.find_element(By.CLASS_NAME, 'detail-summary').find_elements(By.TAG_NAME, 'h5')[1].text.strip()\n",
    "            property_ages.append(property_age)\n",
    "            available_for = container.find_element(By.CLASS_NAME, 'detail-summary').find_elements(By.TAG_NAME, 'h5')[2].text.strip()\n",
    "            available_fors.append(available_for)\n",
    "            immediate_possession = container.find_element(By.CLASS_NAME, 'detail-summary').find_elements(By.TAG_NAME, 'h5')[3].text.strip()\n",
    "            immediate_possessions.append(immediate_possession)\n",
    "\n",
    "        time.sleep(random.uniform(1, 2))\n",
    "\n",
    "    bar.finish()\n",
    "    print(\"Successfully scraped {} pages containing {} properties.\".format(page, len(titles)))\n",
    "\n",
    "    browser.quit()\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'Title': titles,\n",
    "        'Address': addresses,\n",
    "        'Rent(Rs)': rents,\n",
    "        'Deposit(Rs)': deposits,\n",
    "        'Size(Acres)': sizes,\n",
    "        'Furnishing': furnishings,\n",
    "        'Property age': property_ages,\n",
    "        'Available for': available_fors,\n",
    "        'Immediate possession': immediate_possessions\n",
    "    })\n",
    "\n",
    "\n",
    "# Define the URL and maximum number of pages to scrape\n",
    "url = \"https://www.nobroker.in/property/rent/mumbai/Mumbai%20Central?searchParam=W3sibGF0IjoxOC45NjkwMjQ3LCJsb24iOjcyLjgyMDUyOTIsInBsYWNlSWQiOiJDaElKTjNHeG9XN081enNSNF9YTE83R09HZjQiLCJwbGFjZU5hbWUiOiJNdW1iYWkgQ2VudHJhbCJ9XQ==&radius=2.0&sharedAccomodation=0&city=mumbai&locality=Mumbai%20Central\"\n",
    "max_pages = 1000\n",
    "\n",
    "# Scraping rental properties\n",
    "mumbai_rentals = scrape_nobroker_rentals(url, max_pages)\n",
    "\n",
    "# Save data to CSV\n",
    "mumbai_rentals.to_csv('mumbai_rent.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e971167-aa8b-4594-b47e-f6e03f2e9130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "def scrape_nobroker_rentals(url, max_pages):\n",
    "    titles = []\n",
    "    addresses = []\n",
    "    rents = []\n",
    "    sizes = []\n",
    "    deposits = []\n",
    "    furnishings = []\n",
    "    property_ages = []\n",
    "    available_fors = []\n",
    "    immediate_possessions = []\n",
    "\n",
    "    service = Service(executable_path='/snap/bin/geckodriver')\n",
    "    browser = webdriver.Firefox(service=service)\n",
    "\n",
    "    for page in range(1, max_pages + 1):\n",
    "        link = f\"{url}&pageNo={page}\"\n",
    "        browser.get(link)\n",
    "\n",
    "        time.sleep(random.uniform(2, 4))\n",
    "\n",
    "        # Extract data from the current page\n",
    "        house_containers = browser.find_elements(By.CLASS_NAME, \"card\")\n",
    "\n",
    "        if not house_containers:\n",
    "            break\n",
    "\n",
    "        for container in house_containers:\n",
    "            try:\n",
    "                rent = container.find_element(By.XPATH, './/h3[3]/span').text.replace(',', '')\n",
    "                rents.append(int(rent))\n",
    "            except:\n",
    "                rents.append('-')\n",
    "\n",
    "            try:\n",
    "                size = int(container.find_element(By.XPATH, './/h3[1]/span').text.replace(',', ''))\n",
    "                sizes.append(size)\n",
    "            except:\n",
    "                sizes.append('-')\n",
    "\n",
    "            try:\n",
    "                deposit = int(container.find_element(By.XPATH, './/h3[2]/span').text.replace(',', ''))\n",
    "                deposits.append(deposit)\n",
    "            except:\n",
    "                deposits.append('-')\n",
    "\n",
    "            titles.append(container.find_element(By.CLASS_NAME, 'card-header-title').find_element(By.TAG_NAME, 'h2').text.strip())\n",
    "            addresses.append(container.find_element(By.CLASS_NAME, 'card-header-title').find_element(By.TAG_NAME, 'h5').text.strip())\n",
    "            furnishing = container.find_element(By.CLASS_NAME, 'detail-summary').find_elements(By.TAG_NAME, 'h5')[0].text.strip()\n",
    "            furnishings.append(furnishing)\n",
    "            property_age = container.find_element(By.CLASS_NAME, 'detail-summary').find_elements(By.TAG_NAME, 'h5')[1].text.strip()\n",
    "            property_ages.append(property_age)\n",
    "            available_for = container.find_element(By.CLASS_NAME, 'detail-summary').find_elements(By.TAG_NAME, 'h5')[2].text.strip()\n",
    "            available_fors.append(available_for)\n",
    "            immediate_possession = container.find_element(By.CLASS_NAME, 'detail-summary').find_elements(By.TAG_NAME, 'h5')[3].text.strip()\n",
    "            immediate_possessions.append(immediate_possession)\n",
    "\n",
    "        time.sleep(random.uniform(1, 2))\n",
    "\n",
    "    browser.quit()\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'Title': titles,\n",
    "        'Address': addresses,\n",
    "        'Rent(Rs)': rents,\n",
    "        'Deposit(Rs)': deposits,\n",
    "        'Size(Acres)': sizes,\n",
    "        'Furnishing': furnishings,\n",
    "        'Property age': property_ages,\n",
    "        'Available for': available_fors,\n",
    "        'Immediate possession': immediate_possessions\n",
    "    })\n",
    "\n",
    "\n",
    "# Define the URL and maximum number of pages to scrape\n",
    "url = \"https://www.nobroker.in/property/rent/mumbai/Mumbai%20Central?searchParam=W3sibGF0IjoxOC45NjkwMjQ3LCJsb24iOjcyLjgyMDUyOTIsInBsYWNlSWQiOiJDaElKTjNHeG9XN081enNSNF9YTE83R09HZjQiLCJwbGFjZU5hbWUiOiJNdW1iYWkgQ2VudHJhbCJ9XQ==&radius=2.0&sharedAccomodation=0&city=mumbai&locality=Mumbai%20Central\"\n",
    "max_pages = 1000\n",
    "\n",
    "# Scraping rental properties\n",
    "mumbai_rentals = scrape_nobroker_rentals(url, max_pages)\n",
    "\n",
    "# Save data to CSV\n",
    "mumbai_rentals.to_csv('mumbai_rent.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb66275c-6a85-4c33-8d2d-f515df3ea69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting 10 rows!!!\n",
      "10 rows added!!!\n",
      "Row number 10 failed. Trying next one!!!\n",
      "File Exported Sucessfully!!!!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Creating time string to give fie name\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Creating empty list\n",
    "BHK = []\n",
    "Area = []\n",
    "Latitude = []\n",
    "Longitude = []\n",
    "Size = []\n",
    "Deposit = []\n",
    "Rent = []\n",
    "Type = []\n",
    "Age = []\n",
    "For = []\n",
    "Possesion = []\n",
    "Link = []\n",
    "\n",
    "\n",
    "# Function to scrape\n",
    "def scrape_NoBroker(n):\n",
    "    print(f'Exporting {n} rows!!!')\n",
    "\n",
    "    try:\n",
    "        for page in range(int(n / 10)):\n",
    "\n",
    "            try:\n",
    "                print(f'{(page + 1) * 10} rows added!!!')\n",
    "\n",
    "                # Requesting URL\n",
    "                url = requests.get(\n",
    "                    'https://www.nobroker.in/property/rent/bangalore/Bangalore/?searchParam=W3sibGF0IjoxMi45NzE1OTg3LCJsb24iOjc3LjU5NDU2MjcsInBsYWNlSWQiOiJDaElKYlU2MHlYQVdyanNSNEU5LVVlakQzX2ciLCJwbGFjZU5hbWUiOiJCYW5nYWxvcmUifV0=&sharedAccomodation=0&orderBy=nbRank,desc&radius=2&traffic=true&travelTime=30&propertyType=rent&pageNo=' + str(\n",
    "                        page)).text\n",
    "\n",
    "                # Converting from HTML tag to BeautifulSoup object\n",
    "                soup = BeautifulSoup(url, 'lxml')\n",
    "\n",
    "                # Finding all the div tag wich contains all the info\n",
    "                houses = soup.find_all('div', class_='card')\n",
    "\n",
    "                # Looping through each div tag to get individual content\n",
    "                for house in houses:\n",
    "                    BHK.append(house.find('a', class_='card-link-detail')['title'][:1])\n",
    "                    Area_raw = house.find('a', class_='card-link-detail')['title']\n",
    "                    if ',' in Area_raw:\n",
    "                        Area.append(Area_raw.split(',')[-1])\n",
    "                    else:\n",
    "                        Area.append(Area_raw.split('in', 1)[-1])\n",
    "                    Latitude.append(house.find('meta', itemprop='latitude')['content'])\n",
    "                    Longitude.append(house.find('meta', itemprop='longitude')['content'])\n",
    "                    Size.append(house.find_all('meta', itemprop='value')[0]['content'])\n",
    "                    Deposit.append(house.find_all('meta', itemprop='value')[1]['content'])\n",
    "                    Rent.append(house.find_all('meta', itemprop='value')[2]['content'])\n",
    "                    Type.append(house.find_all('h5', class_=\"semi-bold\")[0].text)\n",
    "                    Age.append(house.find_all('h5', class_=\"semi-bold\")[1].text)\n",
    "                    For.append(house.find_all('h5', class_=\"semi-bold\")[2].text.replace('\\n', ''))\n",
    "                    Possesion.append(house.find_all('h5', class_=\"semi-bold\")[3].text.replace('\\n', ''))\n",
    "                    Link.append(house.find('a', class_='card-link-detail')['href'])\n",
    "            except:\n",
    "                print(f'Row number {(page + 1) * 10} failed. Trying next one!!!')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Creating DataFrame and storing data\n",
    "    df = pd.DataFrame(list(zip(BHK, Area, Latitude, Longitude, Size, Deposit, Rent, Type, Age, For, Possesion, Link)),\n",
    "                      columns=['BHK', 'Address', 'Latitude', 'Longitude', 'Size(Acres)', 'Deposit(Rs)', 'Rent(Rs)',\n",
    "                               'Furnishing', 'Property Age', 'Available For', ' Immediate Possesion', 'Link'])\n",
    "\n",
    "    # Exporting DataFrame in form of CSV file\n",
    "    File_name = \"House_Data_\" + timestr + \".csv\"\n",
    "    df.to_csv(File_name, index=False)\n",
    "    print(\"File Exported Sucessfully!!!!\")\n",
    "\n",
    "# Calling fuction to export 10000 rows\n",
    "scrape_NoBroker(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7d21780-9cc9-40fa-8170-2c9cd139afa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting 10 rows!!!\n",
      "10 rows added!!!\n",
      "File Exported Successfully!!!!\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Creating time string to give file name\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Function to scrape\n",
    "def scrape_NoBroker(n):\n",
    "    print(f'Exporting {n} rows!!!')\n",
    "\n",
    "    BHK = []\n",
    "    Area = []\n",
    "    Latitude = []\n",
    "    Longitude = []\n",
    "    Size = []\n",
    "    Deposit = []\n",
    "    Rent = []\n",
    "    Type = []\n",
    "    Age = []\n",
    "    For = []\n",
    "    Possesion = []\n",
    "    Link = []\n",
    "\n",
    "    # Start the browser\n",
    "    service = Service(executable_path='/snap/bin/geckodriver')\n",
    "    browser = webdriver.Firefox(service=service)\n",
    "\n",
    "    try:\n",
    "        for page in range(int(n / 10)):\n",
    "\n",
    "            try:\n",
    "                print(f'{(page + 1) * 10} rows added!!!')\n",
    "\n",
    "                # Requesting URL\n",
    "                url = f'https://www.nobroker.in/property/rent/bangalore/Bangalore/?searchParam=W3sibGF0IjoxMi45NzE1OTg3LCJsb24iOjc3LjU5NDU2MjcsInBsYWNlSWQiOiJDaElKYlU2MHlYQVdyanNSNEU5LVVlakQzX2ciLCJwbGFjZU5hbWUiOiJCYW5nYWxvcmUifV0=&sharedAccomodation=0&orderBy=nbRank,desc&radius=2&traffic=true&travelTime=30&propertyType=rent&pageNo={page}'\n",
    "                browser.get(url)\n",
    "\n",
    "                # Extract data from the current page\n",
    "                house_containers = browser.find_elements(By.CLASS_NAME, \"card\")\n",
    "\n",
    "                for house in house_containers:\n",
    "                    BHK.append(house.find_element(By.CLASS_NAME, 'card-link-detail').get_attribute('title')[:1])\n",
    "                    Area_raw = house.find_element(By.CLASS_NAME, 'card-link-detail').get_attribute('title')\n",
    "                    if ',' in Area_raw:\n",
    "                        Area.append(Area_raw.split(',')[-1])\n",
    "                    else:\n",
    "                        Area.append(Area_raw.split('in', 1)[-1])\n",
    "                    Latitude.append(house.find_element(By.CSS_SELECTOR, 'meta[itemprop=\"latitude\"]').get_attribute('content'))\n",
    "                    Longitude.append(house.find_element(By.CSS_SELECTOR, 'meta[itemprop=\"longitude\"]').get_attribute('content'))\n",
    "                    Size.append(house.find_elements(By.CSS_SELECTOR, 'meta[itemprop=\"value\"]')[0].get_attribute('content'))\n",
    "                    Deposit.append(house.find_elements(By.CSS_SELECTOR, 'meta[itemprop=\"value\"]')[1].get_attribute('content'))\n",
    "                    Rent.append(house.find_elements(By.CSS_SELECTOR, 'meta[itemprop=\"value\"]')[2].get_attribute('content'))\n",
    "                    Type.append(house.find_elements(By.CLASS_NAME, \"semi-bold\")[0].text)\n",
    "                    Age.append(house.find_elements(By.CLASS_NAME, \"semi-bold\")[1].text)\n",
    "                    For.append(house.find_elements(By.CLASS_NAME, \"semi-bold\")[2].text.replace('\\n', ''))\n",
    "                    Possesion.append(house.find_elements(By.CLASS_NAME, \"semi-bold\")[3].text.replace('\\n', ''))\n",
    "                    Link.append(house.find_element(By.CLASS_NAME, 'card-link-detail').get_attribute('href'))\n",
    "            except Exception as e:\n",
    "                print(f'Row number {(page + 1) * 10} failed. Trying next one!!!')\n",
    "                print(e)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    # Creating DataFrame and storing data\n",
    "    df = pd.DataFrame(list(zip(BHK, Area, Latitude, Longitude, Size, Deposit, Rent, Type, Age, For, Possesion, Link)),\n",
    "                      columns=['BHK', 'Address', 'Latitude', 'Longitude', 'Size(Acres)', 'Deposit(Rs)', 'Rent(Rs)',\n",
    "                               'Furnishing', 'Property Age', 'Available For', ' Immediate Possesion', 'Link'])\n",
    "\n",
    "    # Exporting DataFrame in form of CSV file\n",
    "    File_name = \"House_Data_\" + timestr + \".csv\"\n",
    "    df.to_csv(File_name, index=False)\n",
    "    print(\"File Exported Successfully!!!!\")\n",
    "\n",
    "    # Close the browser\n",
    "    browser.quit()\n",
    "\n",
    "# Calling function to export 10000 rows\n",
    "scrape_NoBroker(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7619f018-4761-4066-8330-a8bf8c176551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scraping from URL: https://www.nobroker.in/flats-for-rent-in-pune_pune\n"
     ]
    },
    {
     "ename": "InvalidArgumentException",
     "evalue": "Message: binary is not a Firefox executable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 69\u001b[0m\n\u001b[1;32m     66\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.nobroker.in/flats-for-rent-in-pune_pune\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Call the function to scrape data\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m \u001b[43mscrape_NoBroker\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 27\u001b[0m, in \u001b[0;36mscrape_NoBroker\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     24\u001b[0m Link \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Start the browser\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m driver \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFirefox\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     driver\u001b[38;5;241m.\u001b[39mget(url)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/selenium/webdriver/firefox/webdriver.py:74\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     67\u001b[0m executor \u001b[38;5;241m=\u001b[39m FirefoxRemoteConnection(\n\u001b[1;32m     68\u001b[0m     remote_server_addr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mservice_url,\n\u001b[1;32m     69\u001b[0m     keep_alive\u001b[38;5;241m=\u001b[39mkeep_alive,\n\u001b[1;32m     70\u001b[0m     ignore_proxy\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39m_ignore_local_proxy,\n\u001b[1;32m     71\u001b[0m )\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecutor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquit()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:208\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, command_executor, keep_alive, file_detector, options)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_authenticator_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_client()\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcapabilities\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:292\u001b[0m, in \u001b[0;36mWebDriver.start_session\u001b[0;34m(self, capabilities)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new session with the desired capabilities.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m:Args:\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m - capabilities - a capabilities dict to start the session with.\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    291\u001b[0m caps \u001b[38;5;241m=\u001b[39m _create_caps(capabilities)\n\u001b[0;32m--> 292\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNEW_SESSION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaps\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcaps \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapabilities\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/selenium/webdriver/remote/errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mInvalidArgumentException\u001b[0m: Message: binary is not a Firefox executable\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Creating time string to give file name\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Function to scrape\n",
    "def scrape_NoBroker(url):\n",
    "    print(f'Starting scraping from URL: {url}')\n",
    "\n",
    "    BHK = []\n",
    "    Area = []\n",
    "    Latitude = []\n",
    "    Longitude = []\n",
    "    Size = []\n",
    "    Deposit = []\n",
    "    Rent = []\n",
    "    Type = []\n",
    "    Age = []\n",
    "    For = []\n",
    "    Possesion = []\n",
    "    Link = []\n",
    "\n",
    "    # Start the browser\n",
    "    driver = webdriver.Firefox()\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Let the page load\n",
    "\n",
    "        # Extract data from the page\n",
    "        houses = driver.find_elements(By.CLASS_NAME, \"card\")\n",
    "\n",
    "        for house in houses:\n",
    "            BHK.append(house.find_element(By.CLASS_NAME, 'card-title').text[0])\n",
    "            Area.append(house.find_element(By.CLASS_NAME, 'card-title').text.split(',')[-1])\n",
    "            Latitude.append(house.find_element(By.CSS_SELECTOR, 'meta[itemprop=\"latitude\"]').get_attribute('content'))\n",
    "            Longitude.append(house.find_element(By.CSS_SELECTOR, 'meta[itemprop=\"longitude\"]').get_attribute('content'))\n",
    "            Size.append(house.find_elements(By.CSS_SELECTOR, 'meta[itemprop=\"value\"]')[0].get_attribute('content'))\n",
    "            Deposit.append(house.find_elements(By.CSS_SELECTOR, 'meta[itemprop=\"value\"]')[1].get_attribute('content'))\n",
    "            Rent.append(house.find_elements(By.CSS_SELECTOR, 'meta[itemprop=\"value\"]')[2].get_attribute('content'))\n",
    "            Type.append(house.find_elements(By.CLASS_NAME, \"detail-summary\")[0].text)\n",
    "            Age.append(house.find_elements(By.CLASS_NAME, \"detail-summary\")[1].text)\n",
    "            For.append(house.find_elements(By.CLASS_NAME, \"detail-summary\")[2].text)\n",
    "            Possesion.append(house.find_elements(By.CLASS_NAME, \"detail-summary\")[3].text)\n",
    "            Link.append(house.find_element(By.CLASS_NAME, 'card-title').get_attribute('href'))\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        # Creating DataFrame and storing data\n",
    "        df = pd.DataFrame(list(zip(BHK, Area, Latitude, Longitude, Size, Deposit, Rent, Type, Age, For, Possesion, Link)),\n",
    "                          columns=['BHK', 'Address', 'Latitude', 'Longitude', 'Size(Acres)', 'Deposit(Rs)', 'Rent(Rs)',\n",
    "                                   'Furnishing', 'Property Age', 'Available For', ' Immediate Possesion', 'Link'])\n",
    "\n",
    "        # Exporting DataFrame in form of CSV file\n",
    "        File_name = \"House_Data_\" + timestr + \".csv\"\n",
    "        df.to_csv(File_name, index=False)\n",
    "        print(\"File Exported Successfully!!!!\")\n",
    "\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "\n",
    "# URL to scrape\n",
    "url = \"https://www.nobroker.in/flats-for-rent-in-pune_pune\"\n",
    "\n",
    "# Call the function to scrape data\n",
    "scrape_NoBroker(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ba0599-a8ac-420e-b3b2-4e48d45efefa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ea7bdad-3bb8-49e6-9a76-165c93811b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scraping from URL: https://www.nobroker.in/flats-for-rent-in-pune_pune\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "WebDriver.__init__() got an unexpected keyword argument 'executable_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 69\u001b[0m\n\u001b[1;32m     66\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.nobroker.in/flats-for-rent-in-pune_pune\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Call the function to scrape data\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m \u001b[43mscrape_NoBroker\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 27\u001b[0m, in \u001b[0;36mscrape_NoBroker\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     24\u001b[0m Link \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Start the browser\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m driver \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFirefox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/path/to/geckodriver\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     driver\u001b[38;5;241m.\u001b[39mget(url)\n",
      "\u001b[0;31mTypeError\u001b[0m: WebDriver.__init__() got an unexpected keyword argument 'executable_path'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Creating time string to give file name\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Function to scrape\n",
    "def scrape_NoBroker(url):\n",
    "    print(f'Starting scraping from URL: {url}')\n",
    "\n",
    "    BHK = []\n",
    "    Area = []\n",
    "    Latitude = []\n",
    "    Longitude = []\n",
    "    Size = []\n",
    "    Deposit = []\n",
    "    Rent = []\n",
    "    Type = []\n",
    "    Age = []\n",
    "    For = []\n",
    "    Possesion = []\n",
    "    Link = []\n",
    "\n",
    "    # Start the browser\n",
    "    driver = webdriver.Firefox(executable_path='/path/to/geckodriver')\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Let the page load\n",
    "\n",
    "        # Extract data from the page\n",
    "        houses = driver.find_elements(By.CLASS_NAME, \"card\")\n",
    "\n",
    "        for house in houses:\n",
    "            BHK.append(house.find_element(By.CLASS_NAME, 'card-title').text[0])\n",
    "            Area.append(house.find_element(By.CLASS_NAME, 'card-title').text.split(',')[-1])\n",
    "            Latitude.append(house.find_element(By.CSS_SELECTOR, 'meta[itemprop=\"latitude\"]').get_attribute('content'))\n",
    "            Longitude.append(house.find_element(By.CSS_SELECTOR, 'meta[itemprop=\"longitude\"]').get_attribute('content'))\n",
    "            Size.append(house.find_elements(By.CSS_SELECTOR, 'meta[itemprop=\"value\"]')[0].get_attribute('content'))\n",
    "            Deposit.append(house.find_elements(By.CSS_SELECTOR, 'meta[itemprop=\"value\"]')[1].get_attribute('content'))\n",
    "            Rent.append(house.find_elements(By.CSS_SELECTOR, 'meta[itemprop=\"value\"]')[2].get_attribute('content'))\n",
    "            Type.append(house.find_elements(By.CLASS_NAME, \"detail-summary\")[0].text)\n",
    "            Age.append(house.find_elements(By.CLASS_NAME, \"detail-summary\")[1].text)\n",
    "            For.append(house.find_elements(By.CLASS_NAME, \"detail-summary\")[2].text)\n",
    "            Possesion.append(house.find_elements(By.CLASS_NAME, \"detail-summary\")[3].text)\n",
    "            Link.append(house.find_element(By.CLASS_NAME, 'card-title').get_attribute('href'))\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        # Creating DataFrame and storing data\n",
    "        df = pd.DataFrame(list(zip(BHK, Area, Latitude, Longitude, Size, Deposit, Rent, Type, Age, For, Possesion, Link)),\n",
    "                          columns=['BHK', 'Address', 'Latitude', 'Longitude', 'Size(Acres)', 'Deposit(Rs)', 'Rent(Rs)',\n",
    "                                   'Furnishing', 'Property Age', 'Available For', ' Immediate Possesion', 'Link'])\n",
    "\n",
    "        # Exporting DataFrame in form of CSV file\n",
    "        File_name = \"House_Data_\" + timestr + \".csv\"\n",
    "        df.to_csv(File_name, index=False)\n",
    "        print(\"File Exported Successfully!!!!\")\n",
    "\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "\n",
    "# URL to scrape\n",
    "url = \"https://www.nobroker.in/flats-for-rent-in-pune_pune\"\n",
    "\n",
    "# Call the function to scrape data\n",
    "scrape_NoBroker(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80b909f-d1d3-4898-bb4a-23551a0da327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7446f219-8c10-437c-a6b2-f3e3774f1c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scraping from URL: https://www.nobroker.in/flats-for-rent-in-pune_pune\n"
     ]
    },
    {
     "ename": "NoSuchDriverException",
     "evalue": "Message: Unable to obtain driver for firefox; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/selenium/webdriver/common/driver_finder.py:64\u001b[0m, in \u001b[0;36mDriverFinder._binary_paths\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(path)\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe path is not a valid file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_paths[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdriver_path\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m path\n",
      "\u001b[0;31mValueError\u001b[0m: The path is not a valid file: /path/to/geckodriver",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNoSuchDriverException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 73\u001b[0m\n\u001b[1;32m     70\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.nobroker.in/flats-for-rent-in-pune_pune\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Call the function to scrape data\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m \u001b[43mscrape_NoBroker\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 31\u001b[0m, in \u001b[0;36mscrape_NoBroker\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     29\u001b[0m options \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mFirefoxOptions()\n\u001b[1;32m     30\u001b[0m options\u001b[38;5;241m.\u001b[39mbinary_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/path/to/firefox\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with actual path\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m driver \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFirefox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     driver\u001b[38;5;241m.\u001b[39mget(url)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/selenium/webdriver/firefox/webdriver.py:60\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     57\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;28;01melse\u001b[39;00m Options()\n\u001b[1;32m     59\u001b[0m finder \u001b[38;5;241m=\u001b[39m DriverFinder(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice, options)\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mfinder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_browser_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     61\u001b[0m     options\u001b[38;5;241m.\u001b[39mbinary_location \u001b[38;5;241m=\u001b[39m finder\u001b[38;5;241m.\u001b[39mget_browser_path()\n\u001b[1;32m     62\u001b[0m     options\u001b[38;5;241m.\u001b[39mbrowser_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/selenium/webdriver/common/driver_finder.py:47\u001b[0m, in \u001b[0;36mDriverFinder.get_browser_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_browser_path\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_binary_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrowser_path\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/selenium/webdriver/common/driver_finder.py:78\u001b[0m, in \u001b[0;36mDriverFinder._binary_paths\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     77\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to obtain driver for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbrowser\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoSuchDriverException(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_paths\n",
      "\u001b[0;31mNoSuchDriverException\u001b[0m: Message: Unable to obtain driver for firefox; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c314c6ca-5eb6-4c8d-931d-1b461bae763c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
